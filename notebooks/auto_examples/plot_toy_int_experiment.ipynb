{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Individual Neural Tuning Model on simulated data\n\nThis is a toy experiment to test Individual Tuning Model (INT) on two parts of the\ndata (or different runs) to assess the validity of tuning computation. This code has\nno intention to be an explanatory example, but rather a test to check the validity of\nthe INT model.\n\n\nTo run this example, you must launch IPython via ``ipython\n--matplotlib`` in a terminal, or use ``jupyter-notebook``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\n\nfrom fmralign.alignment_methods import IndividualizedNeuralTuning as INT\nfrom fmralign.fetch_example_data import generate_dummy_signal\nfrom fmralign.hyperalignment.correlation import (\n    compute_pearson_corr,\n    matrix_MDS,\n    stimulus_correlation,\n    tuning_correlation,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate the data\nIn this example we use toy data to test the INT model. We generate two runs of\nthe experiment, and we use the INT model to align the two runs. We then compare\nthe tuning matrices and the shared response to assess the validity of the INT model.\nWe also compare the reconstructed images to the ground truth to assess the validity\nof the INT model.\nThe toy generation function allows us to get the ground truth stimulus and tuning\nmatrices that were used to generate the data, and we can also control the level of\nnoise in the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_subjects = 10\nn_timepoints = 200\nn_voxels = 500\nS_std = 5  # Standard deviation of the source components\nT_std = 1\nSNR = 100  # Signal to noise ratio\nlatent_dim = 15  # if None, latent_dim = n_t\ndecomposition_method = \"pca\"  # if None, SVD is used\n\n\n(\n    data_run_1,\n    data_run_2,\n    stimulus_run_1,\n    stimulus_run_2,\n    data_tuning,\n) = generate_dummy_signal(\n    n_subjects=n_subjects,\n    n_timepoints=n_timepoints,\n    n_voxels=n_voxels,\n    S_std=S_std,\n    T_std=T_std,\n    latent_dim=latent_dim,\n    SNR=SNR,\n    seed=42,\n)\n\nparcels = [range(n_voxels)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create two independant instances of the model\nWe create two instances of the INT model to align the two runs of\nthe experiment, then extract the tuning matrices and the shared from the two\nruns to compare them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "int1 = INT(\n    n_components=latent_dim,\n    parcels=parcels,\n    decomp_method=decomposition_method,\n)\nint2 = INT(\n    n_components=latent_dim,\n    parcels=parcels,\n    decomp_method=decomposition_method,\n)\nint1.fit(data_run_1, verbose=False)\nint2.fit(data_run_2, verbose=False)\n\n# save individual components\ntuning_pred_run_1 = int1.tuning_data\ntuning_pred_run_1 = np.array(tuning_pred_run_1)\ntuning_pred_run_2 = int2.tuning_data\ntuning_pred_run_2 = np.array(tuning_pred_run_2)\n\nstimulus_pred_run_1 = int1.shared_response\nstimulus_pred_run_2 = int2.shared_response\n\ndata_pred = int1.transform(data_run_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting validation metrics\nWe compare the tuning matrices and the shared response to assess the validity\nof the INT model. To achieve that, we use Pearson correlation between true and\nestimated stimulus, as well as between true and estimated tuning matrices.\nFor tuning matrices, this is dones by first computing the correlation between\nevery pair of tuning matrices from the two runs of the experiment, and then\naveraging the correlation across the diagonal (ie the correlation between\nthe same timepoint of the two runs).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 3, figsize=(15, 8))\n\n\n# Tunning matrices\ncorrelation_tuning = tuning_correlation(tuning_pred_run_1, tuning_pred_run_2)\nax[0, 0].imshow(correlation_tuning)\nax[0, 0].set_title(\"Pearson correlation of tuning matrices (Run 1 vs Run 2)\")\nax[0, 0].set_xlabel(\"Subjects, Run 1\")\nax[0, 0].set_ylabel(\"Subjects, Run 2\")\nfig.colorbar(ax[0, 0].imshow(correlation_tuning), ax=ax[0, 0])\n\nrandom_colors = np.random.rand(n_subjects, 3)\n# MDS of predicted images\ncorr_tunning = compute_pearson_corr(data_pred, data_run_2)\ndata_pred_reduced, data_test_reduced = matrix_MDS(\n    data_pred, data_run_2, n_components=2, dissimilarity=1 - corr_tunning\n)\n\nax[0, 1].scatter(\n    data_pred_reduced[:, 0],\n    data_pred_reduced[:, 1],\n    label=\"Run 1\",\n    c=random_colors,\n)\nax[0, 1].scatter(\n    data_test_reduced[:, 0],\n    data_test_reduced[:, 1],\n    label=\"Run 2\",\n    c=random_colors,\n)\nax[0, 1].set_title(\"MDS of predicted images, dim=2\")\n\n# MDS of tunning matrices\ncorr_tunning = compute_pearson_corr(tuning_pred_run_1, tuning_pred_run_2)\nT_first_part_transformed, T_second_part_transformed = matrix_MDS(\n    tuning_pred_run_1,\n    tuning_pred_run_2,\n    n_components=2,\n    dissimilarity=(1 - corr_tunning),\n)\n\nax[0, 2].scatter(\n    T_first_part_transformed[:, 0],\n    T_first_part_transformed[:, 1],\n    label=\"Run 1\",\n    c=random_colors,\n)\nax[0, 2].scatter(\n    T_second_part_transformed[:, 0],\n    T_second_part_transformed[:, 1],\n    label=\"Run 2\",\n    c=random_colors,\n)\nax[0, 2].set_title(\"MDS of tunning matrices, dim=2\")\n# Set square aspect\nax[0, 1].set_aspect(\"equal\", \"box\")\nax[0, 2].set_aspect(\"equal\", \"box\")\n\n# Stimulus matrix correlation\ncorrelation_stimulus_true_est_first_part = stimulus_correlation(\n    stimulus_pred_run_1.T, stimulus_run_1.T\n)\nax[1, 0].imshow(correlation_stimulus_true_est_first_part)\nax[1, 0].set_title(\"Correlation of estimated stimulus vs ground truth (Run 1)\")\nax[1, 0].set_xlabel(\"Latent components, Run 1\")\nax[1, 0].set_ylabel(\"Latent components, ground truth\")\nfig.colorbar(\n    ax[1, 0].imshow(correlation_stimulus_true_est_first_part), ax=ax[1, 0]\n)\n\ncorrelation_stimulus_true_est_second_part = stimulus_correlation(\n    stimulus_pred_run_2.T, stimulus_run_2.T\n)\nax[1, 1].imshow(correlation_stimulus_true_est_second_part)\nax[1, 1].set_title(\n    \"Correlation of estimated stimulus vs ground truth (Run 2))\"\n)\nax[1, 1].set_xlabel(\"Latent components, Run 2\")\nax[1, 1].set_ylabel(\"Latent components, ground truth\")\nfig.colorbar(\n    ax[1, 1].imshow(correlation_stimulus_true_est_second_part), ax=ax[1, 1]\n)\n\n\n# Reconstruction\ncorr_reconstruction = tuning_correlation(data_pred, data_run_2)\nax[1, 2].imshow(corr_reconstruction)\nax[1, 2].set_title(\"Correlation of brain response (Run 2 vs Ground truth)\")\nax[1, 2].set_xlabel(\"Subjects, Run 2\")\nax[1, 2].set_ylabel(\"Subjects, Ground truth\")\nfig.colorbar(ax[1, 2].imshow(corr_reconstruction), ax=ax[1, 2])\n\n\nplt.rc(\"font\", size=10)\n# Define small font for titles\nfig.suptitle(\n    \"Correlation metrics for the Individual Tuning Model\\n\"\n    + f\"{n_subjects} subjects, {n_timepoints} timepoints, {n_voxels} voxels, {latent_dim} latent components\\n\"\n    + f\"SNR={SNR}\"\n)\n\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}