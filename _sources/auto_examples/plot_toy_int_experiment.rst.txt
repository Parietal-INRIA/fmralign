
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_toy_int_experiment.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_toy_int_experiment.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_toy_int_experiment.py:


Co-smoothing Prediction using the IndividualNeuralTuning Model.
See article : https://doi.org/10.1162/imag_a_00032

==========================

This is a toy experiment to test Individual Tuning Model (INT) on two parts of the
data (or different runs) to assess the validity of tuning computation. This code has
no intention to be an explanatory example, but rather a test to check the validity of
the INT model.


To run this example, you must launch IPython via ``ipython
--matplotlib`` in a terminal, or use ``jupyter-notebook``.

.. contents:: **Contents**
    :local:
    :depth: 1

.. GENERATED FROM PYTHON SOURCE LINES 24-35

.. code-block:: Python

    import numpy as np
    import matplotlib.pyplot as plt
    from fmralign.alignment_methods import IndividualizedNeuralTuning as INT
    from fmralign.fetch_example_data import generate_dummy_signal
    from fmralign.hyperalignment.correlation import (
        tuning_correlation,
        stimulus_correlation,
        compute_pearson_corr,
        matrix_MDS,
    )








.. GENERATED FROM PYTHON SOURCE LINES 36-47

##############################################################################
 Generate the data
 -----------------
 In this example we use toy data to test the INT model. We generate two runs of
 the experiment, and we use the INT model to align the two runs. We then compare
 the tuning matrices and the shared response to assess the validity of the INT model.
 We also compare the reconstructed images to the ground truth to assess the validity
 of the INT model.
 The toy generation function allows us to get the ground truth stimulus and tuning
 matrices that were used to generate the data, and we can also control the level of
 noise in the data.

.. GENERATED FROM PYTHON SOURCE LINES 47-77

.. code-block:: Python


    n_subjects = 10
    n_timepoints = 200
    n_voxels = 500
    S_std = 5  # Standard deviation of the source components
    T_std = 1
    SNR = 100  # Signal to noise ratio
    latent_dim = 15  # if None, latent_dim = n_t
    decomposition_method = "pca"  # if None, SVD is used


    (
        data_run_1,
        data_run_2,
        stimulus_run_1,
        stimulus_run_2,
        data_tuning,
    ) = generate_dummy_signal(
        n_subjects=n_subjects,
        n_timepoints=n_timepoints,
        n_voxels=n_voxels,
        S_std=S_std,
        T_std=T_std,
        latent_dim=latent_dim,
        SNR=SNR,
        seed=42,
    )

    parcels = [range(n_voxels)]








.. GENERATED FROM PYTHON SOURCE LINES 78-84

############################################################################
 Create two independant instances of the model
 ---------------------------------------------
 We create two instances of the INT model to align the two runs of
 the experiment, then extract the tuning matrices and the shared from the two
 runs to compare them.

.. GENERATED FROM PYTHON SOURCE LINES 84-109

.. code-block:: Python


    int1 = INT(
        n_components=latent_dim,
        parcels=parcels,
        decomp_method=decomposition_method,
    )
    int2 = INT(
        n_components=latent_dim,
        parcels=parcels,
        decomp_method=decomposition_method,
    )
    int1.fit(data_run_1, verbose=False)
    int2.fit(data_run_2, verbose=False)

    # save individual components
    tuning_pred_run_1 = int1.tuning_data
    tuning_pred_run_1 = np.array(tuning_pred_run_1)
    tuning_pred_run_2 = int2.tuning_data
    tuning_pred_run_2 = np.array(tuning_pred_run_2)

    stimulus_pred_run_1 = int1.shared_response
    stimulus_pred_run_2 = int2.shared_response

    data_pred = int1.transform(data_run_2)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Predict : stimulus matrix shape:  (200, 15)




.. GENERATED FROM PYTHON SOURCE LINES 110-120

##############################################################################
 Plotting validation metrics
 ---------------------------
 We compare the tuning matrices and the shared response to assess the validity
 of the INT model. To achieve that, we use Pearson correlation between true and
 estimated stimulus, as well as between true and estimated tuning matrices.
 For tuning matrices, this is dones by first computing the correlation between
 every pair of tuning matrices from the two runs of the experiment, and then
 averaging the correlation across the diagonal (ie the correlation between
 the same timepoint of the two runs).

.. GENERATED FROM PYTHON SOURCE LINES 120-214

.. code-block:: Python


    fig, ax = plt.subplots(2, 3, figsize=(15, 8))


    # Tunning matrices
    correlation_tuning = tuning_correlation(tuning_pred_run_1, tuning_pred_run_2)
    ax[0, 0].imshow(correlation_tuning)
    ax[0, 0].set_title("Pearson correlation of tuning matrices (Run 1 vs Run 2)")
    ax[0, 0].set_xlabel("Subjects, Run 1")
    ax[0, 0].set_ylabel("Subjects, Run 2")
    fig.colorbar(ax[0, 0].imshow(correlation_tuning), ax=ax[0, 0])

    random_colors = np.random.rand(n_subjects, 3)
    # MDS of predicted images
    corr_tunning = compute_pearson_corr(data_pred, data_run_2)
    data_pred_reduced, data_test_reduced = matrix_MDS(
        data_pred, data_run_2, n_components=2, dissimilarity=1 - corr_tunning
    )

    ax[0, 1].scatter(
        data_pred_reduced[:, 0],
        data_pred_reduced[:, 1],
        label="Run 1",
        c=random_colors,
    )
    ax[0, 1].scatter(
        data_test_reduced[:, 0],
        data_test_reduced[:, 1],
        label="Run 2",
        c=random_colors,
    )
    ax[0, 1].set_title("MDS of predicted images, dim=2")

    # MDS of tunning matrices
    corr_tunning = compute_pearson_corr(tuning_pred_run_1, tuning_pred_run_2)
    T_first_part_transformed, T_second_part_transformed = matrix_MDS(
        tuning_pred_run_1, tuning_pred_run_2, n_components=2, dissimilarity=1 - corr_tunning
    )

    ax[0, 2].scatter(
        T_first_part_transformed[:, 0],
        T_first_part_transformed[:, 1],
        label="Run 1",
        c=random_colors,
    )
    ax[0, 2].scatter(
        T_second_part_transformed[:, 0],
        T_second_part_transformed[:, 1],
        label="Run 2",
        c=random_colors,
    )
    ax[0, 2].set_title("MDS of tunning matrices, dim=2")
    # Set square aspect
    ax[0, 1].set_aspect("equal", "box")
    ax[0, 2].set_aspect("equal", "box")

    # Stimulus matrix correlation
    correlation_stimulus_true_est_first_part = stimulus_correlation(
        stimulus_pred_run_1.T, stimulus_run_1.T
    )
    ax[1, 0].imshow(correlation_stimulus_true_est_first_part)
    ax[1, 0].set_title("Correlation of estimated stimulus vs ground truth (Run 1)")
    ax[1, 0].set_xlabel("Latent components, Run 1")
    ax[1, 0].set_ylabel("Latent components, ground truth")
    fig.colorbar(ax[1, 0].imshow(correlation_stimulus_true_est_first_part), ax=ax[1, 0])

    correlation_stimulus_true_est_second_part = stimulus_correlation(
        stimulus_pred_run_2.T, stimulus_run_2.T
    )
    ax[1, 1].imshow(correlation_stimulus_true_est_second_part)
    ax[1, 1].set_title("Correlation of estimated stimulus vs ground truth (Run 2))")
    ax[1, 1].set_xlabel("Latent components, Run 2")
    ax[1, 1].set_ylabel("Latent components, ground truth")
    fig.colorbar(ax[1, 1].imshow(correlation_stimulus_true_est_second_part), ax=ax[1, 1])


    # Reconstruction
    corr_reconstruction = tuning_correlation(data_pred, data_run_2)
    ax[1, 2].imshow(corr_reconstruction)
    ax[1, 2].set_title("Correlation of brain response (Run 2 vs Ground truth)")
    ax[1, 2].set_xlabel("Subjects, Run 2")
    ax[1, 2].set_ylabel("Subjects, Ground truth")
    fig.colorbar(ax[1, 2].imshow(corr_reconstruction), ax=ax[1, 2])


    plt.rc("font", size=10)
    # Define small font for titles
    fig.suptitle(
        "Correlation metrics for the Individual Tuning Model\n"
        + f"{n_subjects} subjects, {n_timepoints} timepoints, {n_voxels} voxels, {latent_dim} latent components\n"
        + f"SNR={SNR}"
    )

    plt.tight_layout()



.. image-sg:: /auto_examples/images/sphx_glr_plot_toy_int_experiment_001.png
   :alt: Correlation metrics for the Individual Tuning Model 10 subjects, 200 timepoints, 500 voxels, 15 latent components SNR=100, Pearson correlation of tuning matrices (Run 1 vs Run 2), MDS of predicted images, dim=2, MDS of tunning matrices, dim=2, Correlation of estimated stimulus vs ground truth (Run 1), Correlation of estimated stimulus vs ground truth (Run 2)), Correlation of brain response (Run 2 vs Ground truth)
   :srcset: /auto_examples/images/sphx_glr_plot_toy_int_experiment_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 215-216

.. code-block:: Python

    plt.show()








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 5.343 seconds)


.. _sphx_glr_download_auto_examples_plot_toy_int_experiment.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_toy_int_experiment.ipynb <plot_toy_int_experiment.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_toy_int_experiment.py <plot_toy_int_experiment.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_toy_int_experiment.zip <plot_toy_int_experiment.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
