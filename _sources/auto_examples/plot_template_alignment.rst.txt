
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_template_alignment.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_template_alignment.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_template_alignment.py:


Template-based prediction.
==========================

In this tutorial, we show how to better predict new contrasts for a target
subject using many source subjects corresponding contrasts. For this purpose,
we create a template to which we align the target subject, using shared information.
We then predict new images for the target and compare them to a baseline.

We mostly rely on Python common packages and on nilearn to handle
functional data in a clean fashion.


To run this example, you must launch IPython via ``ipython
--matplotlib`` in a terminal, or use ``jupyter-notebook``.

.. GENERATED FROM PYTHON SOURCE LINES 21-31

Retrieve the data
-----------------
In this example we use the IBC dataset, which includes a large number of
different contrasts maps for 12 subjects.
We download the images for subjects sub-01, sub-02, sub-04, sub-05, sub-06
and sub-07 (or retrieve them if they were already downloaded).
imgs is the list of paths to available statistical images for each subjects.
df is a dataframe with metadata about each of them.
mask is a binary image used to extract grey matter regions.


.. GENERATED FROM PYTHON SOURCE LINES 31-38

.. code-block:: Python


    from fmralign.fetch_example_data import fetch_ibc_subjects_contrasts

    imgs, df, mask_img = fetch_ibc_subjects_contrasts(
        ["sub-01", "sub-02", "sub-04", "sub-05", "sub-06", "sub-07"]
    )





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading data from https://osf.io/qn5b6/download ...
     ...done. (2 seconds, 0 min)
    Extracting data from /home/runner/nilearn_data/ibc/cd396fed594eb866baecd48b70ddf7e7/download..... done.
    Downloading data from https://osf.io/u74a3/download ...
    Downloaded 9273344 of 21185350 bytes (43.8%,    1.3s remaining) ...done. (3 seconds, 0 min)
    Extracting data from /home/runner/nilearn_data/ibc/fc5556cc3678df4f4ab566414382180a/download..... done.
    Downloading data from https://osf.io/83bje/download ...
    Downloaded 13049856 of 21188335 bytes (61.6%,    0.6s remaining) ...done. (3 seconds, 0 min)
    Extracting data from /home/runner/nilearn_data/ibc/1beaa1b5a1734a1afbf1c844e1f7a60e/download..... done.
    Downloading data from https://osf.io/43j69/download ...
     ...done. (3 seconds, 0 min)
    Extracting data from /home/runner/nilearn_data/ibc/75e62c44985852e000c2b2865badf72d/download..... done.




.. GENERATED FROM PYTHON SOURCE LINES 39-45

Definine a masker
-----------------
We define a nilearn masker that will be used to handle relevant data.
  For more information, visit :
  'http://nilearn.github.io/manipulating_images/masker_objects.html'


.. GENERATED FROM PYTHON SOURCE LINES 45-50

.. code-block:: Python


    from nilearn.maskers import NiftiMasker

    masker = NiftiMasker(mask_img=mask_img).fit()








.. GENERATED FROM PYTHON SOURCE LINES 51-57

Prepare the data
----------------
For each subject, we will use two series of contrasts acquired during
two independent sessions with a different phase encoding:
Antero-posterior(AP) or Postero-anterior(PA).


.. GENERATED FROM PYTHON SOURCE LINES 57-77

.. code-block:: Python



    # To infer a template for subjects sub-01 to sub-06 for both AP and PA data,
    # we make a list of 4D niimgs from our list of list of files containing 3D images

    from nilearn.image import concat_imgs

    template_train = []
    for i in range(5):
        template_train.append(concat_imgs(imgs[i]))
    target_train = df[df.subject == "sub-07"][df.acquisition == "ap"].path.values

    # For subject sub-07, we split it in two folds:
    #   - target train: sub-07 AP contrasts, used to learn alignment to template
    #   - target test: sub-07 PA contrasts, used as a ground truth to score predictions
    # We make a single 4D Niimg from our list of 3D filenames

    target_train = concat_imgs(target_train)
    target_test = df[df.subject == "sub-07"][df.acquisition == "pa"].path.values





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/fmralign/fmralign/examples/plot_template_alignment.py:67: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
      target_train = df[df.subject == "sub-07"][df.acquisition == "ap"].path.values
    /home/runner/work/fmralign/fmralign/examples/plot_template_alignment.py:75: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
      target_test = df[df.subject == "sub-07"][df.acquisition == "pa"].path.values




.. GENERATED FROM PYTHON SOURCE LINES 78-83

Compute a baseline (average of subjects)
----------------------------------------
We create an image with as many contrasts as any subject representing for
each contrast the average of all train subjects maps.


.. GENERATED FROM PYTHON SOURCE LINES 83-90

.. code-block:: Python


    import numpy as np

    masked_imgs = [masker.transform(img) for img in template_train]
    average_img = np.mean(masked_imgs, axis=0)
    average_subject = masker.inverse_transform(average_img)








.. GENERATED FROM PYTHON SOURCE LINES 91-101

Create a template from the training subjects.
---------------------------------------------
We define an estimator using the class TemplateAlignment:
  * We align the whole brain through 'multiple' local alignments.
  * These alignments are calculated on a parcellation of the brain in 150 pieces,
    this parcellation creates group of functionnally similar voxels.
  * The template is created iteratively, aligning all subjects data into a
    common space, from which the template is inferred and aligning again to this
    new template space.


.. GENERATED FROM PYTHON SOURCE LINES 101-111

.. code-block:: Python


    from nilearn.image import index_img

    from fmralign.template_alignment import TemplateAlignment

    template_estim = TemplateAlignment(
        n_pieces=150, alignment_method="ridge_cv", mask=masker
    )
    template_estim.fit(template_train)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter detrend :
        Masker parameter False - overriding estimator parameter None

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)




.. GENERATED FROM PYTHON SOURCE LINES 112-120

Predict new data for left-out subject
-------------------------------------
We use target_train data to fit the transform, indicating it corresponds to
the contrasts indexed by train_index and predict from this learnt alignment
contrasts corresponding to template test_index numbers.
For each train subject and for the template, the AP contrasts are sorted from
0, to 53, and then the PA contrasts from 53 to 106.


.. GENERATED FROM PYTHON SOURCE LINES 120-135

.. code-block:: Python


    train_index = range(53)
    test_index = range(53, 106)

    # We input the mapping image target_train in a list, we could have input more
    # than one subject for which we'd want to predict : [train_1, train_2 ...]

    prediction_from_template = template_estim.transform(
        [target_train], train_index, test_index
    )

    # As a baseline prediction, let's just take the average of activations across subjects.

    prediction_from_average = index_img(average_subject, test_index)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /opt/hostedtoolcache/Python/3.11.10/x64/lib/python3.11/site-packages/nilearn/_utils/masker_validation.py:113: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      warnings.warn(warn_str)
    /home/runner/work/fmralign/fmralign/fmralign/_utils.py:69: UserWarning: 
     Some parcels are more than 1000 voxels wide it can slow down alignment,especially optimal_transport :
     parcel 84 : 1105 voxels
      warnings.warn(warning)




.. GENERATED FROM PYTHON SOURCE LINES 136-143

Score the baseline and the prediction
-------------------------------------
We use a utility scoring function to measure the voxelwise correlation
between the prediction and the ground truth. That is, for each voxel, we
measure the correlation between its profile of activation without and with
alignment, to see if alignment was able to predict a signal more alike the ground truth.


.. GENERATED FROM PYTHON SOURCE LINES 143-157

.. code-block:: Python


    from fmralign.metrics import score_voxelwise

    # Now we use this scoring function to compare the correlation of predictions
    # made from group average and from template with the real PA contrasts of sub-07

    average_score = masker.inverse_transform(
        score_voxelwise(target_test, prediction_from_average, masker, loss="corr")
    )
    template_score = masker.inverse_transform(
        score_voxelwise(target_test, prediction_from_template[0], masker, loss="corr")
    )









.. GENERATED FROM PYTHON SOURCE LINES 158-162

Plotting the measures
---------------------
Finally we plot both scores


.. GENERATED FROM PYTHON SOURCE LINES 162-174

.. code-block:: Python


    from nilearn import plotting

    baseline_display = plotting.plot_stat_map(
        average_score, display_mode="z", vmax=1, cut_coords=[-15, -5]
    )
    baseline_display.title("Group average correlation wt ground truth")
    display = plotting.plot_stat_map(
        template_score, display_mode="z", cut_coords=[-15, -5], vmax=1
    )
    display.title("Template-based prediction correlation wt ground truth")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_template_alignment_001.png
         :alt: plot template alignment
         :srcset: /auto_examples/images/sphx_glr_plot_template_alignment_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_template_alignment_002.png
         :alt: plot template alignment
         :srcset: /auto_examples/images/sphx_glr_plot_template_alignment_002.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 175-178

We observe that creating a template and aligning a new subject to it yields
a prediction that is better correlated with the ground truth than just using
the average activations of subjects.


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (22 minutes 15.630 seconds)


.. _sphx_glr_download_auto_examples_plot_template_alignment.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/plot_template_alignment.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_template_alignment.ipynb <plot_template_alignment.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_template_alignment.py <plot_template_alignment.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_template_alignment.zip <plot_template_alignment.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
