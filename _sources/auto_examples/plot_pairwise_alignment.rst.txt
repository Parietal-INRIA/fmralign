
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_pairwise_alignment.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_plot_pairwise_alignment.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_pairwise_alignment.py:


Pairwise functional alignment.
==============================

In this tutorial, we show how to better predict new contrasts for a target
subject using source subject corresponding contrasts and data in common.

We mostly rely on python common packages and on nilearn to handle functional
data in a clean fashion.


To run this example, you must launch IPython via ``ipython
--matplotlib`` in a terminal, or use ``jupyter-notebook``.

.. GENERATED FROM PYTHON SOURCE LINES 18-27

Retrieve the data
-----------------
In this example we use the IBC dataset, which include a large number of
different contrasts maps for 12 subjects. We download the images for
subjects sub-01 and sub-02 (or retrieve them if they were already downloaded)
Files is the list of paths for each subjects.
df is a dataframe with metadata about each of them.
mask is an appropriate nifti image to select the data.


.. GENERATED FROM PYTHON SOURCE LINES 27-32

.. code-block:: Python


    from fmralign.fetch_example_data import fetch_ibc_subjects_contrasts

    files, df, mask = fetch_ibc_subjects_contrasts(["sub-01", "sub-02"])





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [_add_readme_to_default_data_locations] Added README.md to 
    /home/runner/nilearn_data
    [get_dataset_dir] Dataset created in /home/runner/nilearn_data/ibc
    [fetch_single_file] Downloading data from https://osf.io/pcvje/download ...
    [fetch_single_file]  ...done. (1 seconds, 0 min)

    [uncompress_file] Extracting data from 
    /home/runner/nilearn_data/ibc/8e275a34345802c5c273312d85957d6c/download...
    [uncompress_file] .. done.

    [fetch_single_file] Downloading data from https://osf.io/yvju3/download ...
    [fetch_single_file]  ...done. (2 seconds, 0 min)

    [uncompress_file] Extracting data from 
    /home/runner/nilearn_data/ibc/fe06df963fcb3fd454f63a33f0864e8d/download...
    [uncompress_file] .. done.

    [fetch_single_file] Downloading data from https://osf.io/8z23h/download ...
    [_chunk_report_] Downloaded 20963328 of 21185337 bytes (99.0%%,    0.0s 
    remaining)
    [fetch_single_file]  ...done. (4 seconds, 0 min)

    [uncompress_file] Extracting data from 
    /home/runner/nilearn_data/ibc/100352739b7501f0ed04920933b4be36/download...
    [uncompress_file] .. done.

    [fetch_single_file] Downloading data from https://osf.io/e9kbm/download ...
    [_chunk_report_] Downloaded 16842752 of 21196887 bytes (79.5%%,    0.3s 
    remaining)
    [fetch_single_file]  ...done. (3 seconds, 0 min)

    [uncompress_file] Extracting data from 
    /home/runner/nilearn_data/ibc/331a0a579c6e46c0911502a96215b358/download...
    [uncompress_file] .. done.





.. GENERATED FROM PYTHON SOURCE LINES 33-39

Define a masker
---------------
We define a nilearn masker that will be used to handle relevant data.
  For more information, visit :
  'http://nilearn.github.io/manipulating_images/masker_objects.html'


.. GENERATED FROM PYTHON SOURCE LINES 39-47

.. code-block:: Python


    from nilearn.image import concat_imgs
    from nilearn.maskers import NiftiMasker

    masker = NiftiMasker(mask_img=mask)
    mask
    masker.fit()






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <style>#sk-container-id-1 {
      /* Definition of color scheme common for light and dark mode */
      --sklearn-color-text: black;
      --sklearn-color-line: gray;
      /* Definition of color scheme for unfitted estimators */
      --sklearn-color-unfitted-level-0: #fff5e6;
      --sklearn-color-unfitted-level-1: #f6e4d2;
      --sklearn-color-unfitted-level-2: #ffe0b3;
      --sklearn-color-unfitted-level-3: chocolate;
      /* Definition of color scheme for fitted estimators */
      --sklearn-color-fitted-level-0: #f0f8ff;
      --sklearn-color-fitted-level-1: #d4ebff;
      --sklearn-color-fitted-level-2: #b3dbfd;
      --sklearn-color-fitted-level-3: cornflowerblue;

      /* Specific color for light theme */
      --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
      --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
      --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
      --sklearn-color-icon: #696969;

      @media (prefers-color-scheme: dark) {
        /* Redefinition of color scheme for dark theme */
        --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
        --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
        --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
        --sklearn-color-icon: #878787;
      }
    }

    #sk-container-id-1 {
      color: var(--sklearn-color-text);
    }

    #sk-container-id-1 pre {
      padding: 0;
    }

    #sk-container-id-1 input.sk-hidden--visually {
      border: 0;
      clip: rect(1px 1px 1px 1px);
      clip: rect(1px, 1px, 1px, 1px);
      height: 1px;
      margin: -1px;
      overflow: hidden;
      padding: 0;
      position: absolute;
      width: 1px;
    }

    #sk-container-id-1 div.sk-dashed-wrapped {
      border: 1px dashed var(--sklearn-color-line);
      margin: 0 0.4em 0.5em 0.4em;
      box-sizing: border-box;
      padding-bottom: 0.4em;
      background-color: var(--sklearn-color-background);
    }

    #sk-container-id-1 div.sk-container {
      /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
         but bootstrap.min.css set `[hidden] { display: none !important; }`
         so we also need the `!important` here to be able to override the
         default hidden behavior on the sphinx rendered scikit-learn.org.
         See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
      display: inline-block !important;
      position: relative;
    }

    #sk-container-id-1 div.sk-text-repr-fallback {
      display: none;
    }

    div.sk-parallel-item,
    div.sk-serial,
    div.sk-item {
      /* draw centered vertical line to link estimators */
      background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
      background-size: 2px 100%;
      background-repeat: no-repeat;
      background-position: center center;
    }

    /* Parallel-specific style estimator block */

    #sk-container-id-1 div.sk-parallel-item::after {
      content: "";
      width: 100%;
      border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
      flex-grow: 1;
    }

    #sk-container-id-1 div.sk-parallel {
      display: flex;
      align-items: stretch;
      justify-content: center;
      background-color: var(--sklearn-color-background);
      position: relative;
    }

    #sk-container-id-1 div.sk-parallel-item {
      display: flex;
      flex-direction: column;
    }

    #sk-container-id-1 div.sk-parallel-item:first-child::after {
      align-self: flex-end;
      width: 50%;
    }

    #sk-container-id-1 div.sk-parallel-item:last-child::after {
      align-self: flex-start;
      width: 50%;
    }

    #sk-container-id-1 div.sk-parallel-item:only-child::after {
      width: 0;
    }

    /* Serial-specific style estimator block */

    #sk-container-id-1 div.sk-serial {
      display: flex;
      flex-direction: column;
      align-items: center;
      background-color: var(--sklearn-color-background);
      padding-right: 1em;
      padding-left: 1em;
    }


    /* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
    clickable and can be expanded/collapsed.
    - Pipeline and ColumnTransformer use this feature and define the default style
    - Estimators will overwrite some part of the style using the `sk-estimator` class
    */

    /* Pipeline and ColumnTransformer style (default) */

    #sk-container-id-1 div.sk-toggleable {
      /* Default theme specific background. It is overwritten whether we have a
      specific estimator or a Pipeline/ColumnTransformer */
      background-color: var(--sklearn-color-background);
    }

    /* Toggleable label */
    #sk-container-id-1 label.sk-toggleable__label {
      cursor: pointer;
      display: block;
      width: 100%;
      margin-bottom: 0;
      padding: 0.5em;
      box-sizing: border-box;
      text-align: center;
    }

    #sk-container-id-1 label.sk-toggleable__label-arrow:before {
      /* Arrow on the left of the label */
      content: "▸";
      float: left;
      margin-right: 0.25em;
      color: var(--sklearn-color-icon);
    }

    #sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
      color: var(--sklearn-color-text);
    }

    /* Toggleable content - dropdown */

    #sk-container-id-1 div.sk-toggleable__content {
      max-height: 0;
      max-width: 0;
      overflow: hidden;
      text-align: left;
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-1 div.sk-toggleable__content.fitted {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    #sk-container-id-1 div.sk-toggleable__content pre {
      margin: 0.2em;
      border-radius: 0.25em;
      color: var(--sklearn-color-text);
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-1 div.sk-toggleable__content.fitted pre {
      /* unfitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    #sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
      /* Expand drop-down */
      max-height: 200px;
      max-width: 100%;
      overflow: auto;
    }

    #sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
      content: "▾";
    }

    /* Pipeline/ColumnTransformer-specific style */

    #sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Estimator-specific style */

    /* Colorize estimator box */
    #sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-2);
    }

    #sk-container-id-1 div.sk-label label.sk-toggleable__label,
    #sk-container-id-1 div.sk-label label {
      /* The background is the default theme color */
      color: var(--sklearn-color-text-on-default-background);
    }

    /* On hover, darken the color of the background */
    #sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    /* Label box, darken color on hover, fitted */
    #sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
      color: var(--sklearn-color-text);
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Estimator label */

    #sk-container-id-1 div.sk-label label {
      font-family: monospace;
      font-weight: bold;
      display: inline-block;
      line-height: 1.2em;
    }

    #sk-container-id-1 div.sk-label-container {
      text-align: center;
    }

    /* Estimator-specific */
    #sk-container-id-1 div.sk-estimator {
      font-family: monospace;
      border: 1px dotted var(--sklearn-color-border-box);
      border-radius: 0.25em;
      box-sizing: border-box;
      margin-bottom: 0.5em;
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-0);
    }

    #sk-container-id-1 div.sk-estimator.fitted {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-0);
    }

    /* on hover */
    #sk-container-id-1 div.sk-estimator:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-2);
    }

    #sk-container-id-1 div.sk-estimator.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-2);
    }

    /* Specification for estimator info (e.g. "i" and "?") */

    /* Common style for "i" and "?" */

    .sk-estimator-doc-link,
    a:link.sk-estimator-doc-link,
    a:visited.sk-estimator-doc-link {
      float: right;
      font-size: smaller;
      line-height: 1em;
      font-family: monospace;
      background-color: var(--sklearn-color-background);
      border-radius: 1em;
      height: 1em;
      width: 1em;
      text-decoration: none !important;
      margin-left: 1ex;
      /* unfitted */
      border: var(--sklearn-color-unfitted-level-1) 1pt solid;
      color: var(--sklearn-color-unfitted-level-1);
    }

    .sk-estimator-doc-link.fitted,
    a:link.sk-estimator-doc-link.fitted,
    a:visited.sk-estimator-doc-link.fitted {
      /* fitted */
      border: var(--sklearn-color-fitted-level-1) 1pt solid;
      color: var(--sklearn-color-fitted-level-1);
    }

    /* On hover */
    div.sk-estimator:hover .sk-estimator-doc-link:hover,
    .sk-estimator-doc-link:hover,
    div.sk-label-container:hover .sk-estimator-doc-link:hover,
    .sk-estimator-doc-link:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
    .sk-estimator-doc-link.fitted:hover,
    div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
    .sk-estimator-doc-link.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    /* Span, style for the box shown on hovering the info icon */
    .sk-estimator-doc-link span {
      display: none;
      z-index: 9999;
      position: relative;
      font-weight: normal;
      right: .2ex;
      padding: .5ex;
      margin: .5ex;
      width: min-content;
      min-width: 20ex;
      max-width: 50ex;
      color: var(--sklearn-color-text);
      box-shadow: 2pt 2pt 4pt #999;
      /* unfitted */
      background: var(--sklearn-color-unfitted-level-0);
      border: .5pt solid var(--sklearn-color-unfitted-level-3);
    }

    .sk-estimator-doc-link.fitted span {
      /* fitted */
      background: var(--sklearn-color-fitted-level-0);
      border: var(--sklearn-color-fitted-level-3);
    }

    .sk-estimator-doc-link:hover span {
      display: block;
    }

    /* "?"-specific style due to the `<a>` HTML tag */

    #sk-container-id-1 a.estimator_doc_link {
      float: right;
      font-size: 1rem;
      line-height: 1em;
      font-family: monospace;
      background-color: var(--sklearn-color-background);
      border-radius: 1rem;
      height: 1rem;
      width: 1rem;
      text-decoration: none;
      /* unfitted */
      color: var(--sklearn-color-unfitted-level-1);
      border: var(--sklearn-color-unfitted-level-1) 1pt solid;
    }

    #sk-container-id-1 a.estimator_doc_link.fitted {
      /* fitted */
      border: var(--sklearn-color-fitted-level-1) 1pt solid;
      color: var(--sklearn-color-fitted-level-1);
    }

    /* On hover */
    #sk-container-id-1 a.estimator_doc_link:hover {
      /* unfitted */
      background-color: var(--sklearn-color-unfitted-level-3);
      color: var(--sklearn-color-background);
      text-decoration: none;
    }

    #sk-container-id-1 a.estimator_doc_link.fitted:hover {
      /* fitted */
      background-color: var(--sklearn-color-fitted-level-3);
    }
    </style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>NiftiMasker(mask_img=&#x27;/home/runner/nilearn_data/ibc/gm_mask_3mm.nii.gz&#x27;,
                memory=Memory(location=None))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;NiftiMasker<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>NiftiMasker(mask_img=&#x27;/home/runner/nilearn_data/ibc/gm_mask_3mm.nii.gz&#x27;,
                memory=Memory(location=None))</pre></div> </div></div></div></div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 48-58

Prepare the data
----------------
For each subject, for each task and conditions, our dataset contains two
independent acquisitions, similar except for one acquisition parameter, the
encoding phase used that was either Antero-Posterior (AP) or Postero-Anterior (PA).

Although this induces small differences in the final data, we will take
advantage of these "duplicates to create a training and a testing set that
contains roughly the same signals but acquired totally independently.


.. GENERATED FROM PYTHON SOURCE LINES 58-84

.. code-block:: Python


    # The training fold, used to learn alignment from source subject toward target:
    # * source train: AP contrasts for subject sub-01
    # * target train: AP contrasts for subject sub-02

    source_train = concat_imgs(
        df[df.subject == "sub-01"][df.acquisition == "ap"].path.values
    )
    target_train = concat_imgs(
        df[df.subject == "sub-02"][df.acquisition == "ap"].path.values
    )

    # The testing fold:
    # * source test: PA contrasts for subject sub-01, used to predict
    #   the corresponding contrasts of subject sub-02
    # * target test: PA contrasts for subject sub-02, used as a ground truth
    #   to score our predictions

    source_test = concat_imgs(
        df[df.subject == "sub-01"][df.acquisition == "pa"].path.values
    )
    target_test = concat_imgs(
        df[df.subject == "sub-02"][df.acquisition == "pa"].path.values
    )






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /home/runner/work/fmralign/fmralign/examples/plot_pairwise_alignment.py:64: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
      df[df.subject == "sub-01"][df.acquisition == "ap"].path.values
    /home/runner/work/fmralign/fmralign/examples/plot_pairwise_alignment.py:67: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
      df[df.subject == "sub-02"][df.acquisition == "ap"].path.values
    /home/runner/work/fmralign/fmralign/examples/plot_pairwise_alignment.py:77: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
      df[df.subject == "sub-01"][df.acquisition == "pa"].path.values
    /home/runner/work/fmralign/fmralign/examples/plot_pairwise_alignment.py:80: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
      df[df.subject == "sub-02"][df.acquisition == "pa"].path.values




.. GENERATED FROM PYTHON SOURCE LINES 85-93

Define the estimator, fit it and predict
----------------------------------------
To proceed with alignment we use PairwiseAlignment class. We will use the
common model proposed in the literature:
* we will align the whole brain through multiple local alignments.
* these alignments are calculated on a parcellation of the brain in 150
  pieces, this parcellation creates group of functionnally similar voxels.


.. GENERATED FROM PYTHON SOURCE LINES 93-104

.. code-block:: Python


    from fmralign.pairwise_alignment import PairwiseAlignment

    alignment_estimator = PairwiseAlignment(
        alignment_method="scaled_orthogonal", n_pieces=150, mask=masker
    )
    # Learn alignment operator from subject 1 to subject 2 on training data
    alignment_estimator.fit(source_train, target_train)
    # Predict test data for subject 2 from subject 1
    target_pred = alignment_estimator.transform(source_test)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [PairwiseAlignment.fit] Resampling mask
    /home/runner/work/fmralign/fmralign/fmralign/_utils.py:251: UserWarning: Overriding provided-default estimator parameters with provided masker parameters :
    Parameter mask_strategy :
        Masker parameter background - overriding estimator parameter epi
    Parameter smoothing_fwhm :
        Masker parameter None - overriding estimator parameter 4.0

      parcellation.fit(images_to_parcel)
    [PairwiseAlignment.fit] Resampling mask




.. GENERATED FROM PYTHON SOURCE LINES 105-112

Score the baseline and the prediction
-------------------------------------
We use a utility scoring function to measure the voxelwise correlation between
the prediction and the ground truth. That is, for each voxel, we measure the
correlation between its profile of activation without and with alignment,
to see if alignment was able to predict a signal more alike the ground truth.


.. GENERATED FROM PYTHON SOURCE LINES 112-125

.. code-block:: Python


    from fmralign.metrics import score_voxelwise

    # Now we use this scoring function to compare the correlation of aligned and
    # original data from sub-01 made with the real PA contrasts of sub-02.

    baseline_score = masker.inverse_transform(
        score_voxelwise(target_test, source_test, masker, loss="corr")
    )
    aligned_score = masker.inverse_transform(
        score_voxelwise(target_test, target_pred, masker, loss="corr")
    )








.. GENERATED FROM PYTHON SOURCE LINES 126-130

Plotting the measures
---------------------
Finally we plot both scores


.. GENERATED FROM PYTHON SOURCE LINES 130-142

.. code-block:: Python


    from nilearn import plotting

    baseline_display = plotting.plot_stat_map(
        baseline_score, display_mode="z", vmax=1, cut_coords=[-15, -5]
    )
    baseline_display.title("Baseline correlation wt ground truth")
    display = plotting.plot_stat_map(
        aligned_score, display_mode="z", cut_coords=[-15, -5], vmax=1
    )
    display.title("Prediction correlation wt ground truth")




.. rst-class:: sphx-glr-horizontal


    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_pairwise_alignment_001.png
         :alt: plot pairwise alignment
         :srcset: /auto_examples/images/sphx_glr_plot_pairwise_alignment_001.png
         :class: sphx-glr-multi-img

    *

      .. image-sg:: /auto_examples/images/sphx_glr_plot_pairwise_alignment_002.png
         :alt: plot pairwise alignment
         :srcset: /auto_examples/images/sphx_glr_plot_pairwise_alignment_002.png
         :class: sphx-glr-multi-img





.. GENERATED FROM PYTHON SOURCE LINES 143-146

We can see on the plot that after alignment the prediction made for one
subject data, informed by another subject are greatly improved.



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 40.628 seconds)


.. _sphx_glr_download_auto_examples_plot_pairwise_alignment.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/nilearn/nilearn/main?urlpath=lab/tree/notebooks/auto_examples/plot_pairwise_alignment.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_pairwise_alignment.ipynb <plot_pairwise_alignment.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_pairwise_alignment.py <plot_pairwise_alignment.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_pairwise_alignment.zip <plot_pairwise_alignment.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
